{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8b8a78e-963c-43ae-8236-f56ef50a78b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/21 16:33:10 WARN Utils: Your hostname, QuzihandeMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.12.115.210 instead (on interface en0)\n",
      "22/09/21 16:33:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/21 16:33:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/09/21 16:33:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/09/21 16:33:12 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/09/21 16:33:12 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/09/21 16:33:12 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/09/21 16:33:12 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "22/09/21 16:33:12 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "22/09/21 16:33:12 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.functions import col, isnan, when, count, mean, udf, split, unix_timestamp, from_unixtime, lower\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType\n",
    "\n",
    "# init SparkSession class\n",
    "spark = (\n",
    "    # if available consider use yarn master node\n",
    "    SparkSession.builder.master(\"local[*]\") \n",
    "    \n",
    "    # spark executor env configuratio\n",
    "    .config(\"spark.executor.memory\", \"8g\")\n",
    "    .config(\"spark.driver.memory\", \"16g\")\n",
    "    .config(\"spark.executor.cores\", \"2\")\n",
    "    .config(\"spark.executor.instances\", \"6\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    \n",
    "    # jvm memory configuration\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\")\n",
    "    .config(\"spark.memory.offHeap.size\", \"8g\")\n",
    "    \n",
    "    # parquet file load configuration\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", 'true')\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", 'true')\n",
    "    \n",
    "    # build the session\n",
    "    .appName(\"Pyspark Start Template\") # change app name here\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# change default log level\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "\n",
    "# import libaries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import geopandas as gdp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import pickle\n",
    "# WARNNING message is result by JVM environment setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99fc50bc-71a2-48fb-9ea3-d3bee57641ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15260"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet('../../data/raw/domain-website-data/*')\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "404b2f46-f483-4306-83d2-6e0f82c584ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15260"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_url = df.select('url').toPandas()\n",
    "len(df_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba231c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=set(df_url['url'][:2])\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2efa6177-bf84-44bf-856e-fbc2652d58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('link', 'wb') as file:\n",
    "    pickle.dump(a, file, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e026d280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/21 16:39:07 WARN Utils: Your hostname, QuzihandeMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.12.115.210 instead (on interface en0)\n",
      "22/09/21 16:39:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/21 16:39:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/09/21 16:39:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/09/21 16:39:08 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/09/21 16:39:08 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/09/21 16:39:08 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/09/21 16:39:08 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "22/09/21 16:39:08 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "22/09/21 16:39:08 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.functions import col, isnan, when, count, mean, udf, split, unix_timestamp, from_unixtime, lower\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType\n",
    "\n",
    "# init SparkSession class\n",
    "spark = (\n",
    "    # if available consider use yarn master node\n",
    "    SparkSession.builder.master(\"local[*]\") \n",
    "    \n",
    "    # spark executor env configuratio\n",
    "    .config(\"spark.executor.memory\", \"8g\")\n",
    "    .config(\"spark.driver.memory\", \"16g\")\n",
    "    .config(\"spark.executor.cores\", \"2\")\n",
    "    .config(\"spark.executor.instances\", \"6\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    \n",
    "    # jvm memory configuration\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\")\n",
    "    .config(\"spark.memory.offHeap.size\", \"8g\")\n",
    "    \n",
    "    # parquet file load configuration\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", 'true')\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", 'true')\n",
    "    \n",
    "    # build the session\n",
    "    .appName(\"Pyspark Start Template\") # change app name here\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# change default log level\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "\n",
    "# import libaries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import geopandas as gdp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import pickle\n",
    "# WARNNING message is result by JVM environment setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260b54b6-a4c8-4292-bc3d-9fd43bf62da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('link', 'rb') as file:\n",
    "    links = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4708b087-7d91-4c04-a145-7e10873f40cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c20b083-91b5-44d9-ac27-c2b2b05f250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../scripts/school2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b9bcffa-af1f-4746-9975-cdc3852cd319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postcode</th>\n",
       "      <th>nearBySchools</th>\n",
       "      <th>nearBySchools_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>[Ozford College, Ozford College - Ozford Colle...</td>\n",
       "      <td>[306.93672546572753, 307.96525885360074, 347.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>[Eltham College - Lonsdale Street Campus, Stot...</td>\n",
       "      <td>[414.7984287814513, 539.2674293055095, 678.127...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  postcode                                      nearBySchools  \\\n",
       "0     3000  [Ozford College, Ozford College - Ozford Colle...   \n",
       "0     3000  [Eltham College - Lonsdale Street Campus, Stot...   \n",
       "\n",
       "                              nearBySchools_distance  \n",
       "0  [306.93672546572753, 307.96525885360074, 347.9...  \n",
       "0  [414.7984287814513, 539.2674293055095, 678.127...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from domain_scraper import *\n",
    "domain_properties_info(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f9dd945-07f4-4a51-831b-c157c65f2f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.parquet('../../scripts/school2/1/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbc8b47f-fef8-4601-9cc2-2226316435bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df2.select('nearBySchools').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f149c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nearBySchools</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Eltham College - Lonsdale Street Campus, Stot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Ozford College, Ozford College - Ozford Colle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       nearBySchools\n",
       "0  [Eltham College - Lonsdale Street Campus, Stot...\n",
       "1  [Ozford College, Ozford College - Ozford Colle..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deea7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff71f337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://www.domain.com.au/101-25-33-wills-street-melbourne-vic-3000-14868152',\n",
       " 'https://www.domain.com.au/104-300-swanston-street-melbourne-vic-3000-13671355'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec25d646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADS",
   "language": "python",
   "name": "ads"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
